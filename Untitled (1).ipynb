{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b786a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4403,), (4403,), (1887,), (1887,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "from jieba import analyse\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"ChnSentiCorp_htl_all.csv\")\n",
    "data[\"review\"] = data[\"review\"].astype('str')\n",
    "\n",
    "\n",
    "strinfo1 = re.compile('[0-9]|酒店|携程|年月日|北京|上海|重庆|广州|杭州|南京|成都|苏州|西安|东莞|长沙|济南|深圳|西路|东路')\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: strinfo1.sub('', x))\n",
    "# 由于有的时候jupyternotebook会出bug,去除一次并不能去除掉年月日，所以保险起见，再去除一次\n",
    "strinfo2 = re.compile('[0-9]|酒店|携程|年月日')\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: strinfo2.sub('', x))\n",
    "# 第一步 将空字符的行替换为nan，方便进行删除\n",
    "data.replace(to_replace=r'^\\s*$', value=np.nan, regex=True, inplace=True)\n",
    "data.replace(to_replace=r'[a-zA-Z]', value=np.nan, regex=True, inplace=True)\n",
    "# 第二步 删除所有值为nan的行\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF  # 原始文本转化为tf-idf的特征矩阵\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# 将有标签的数据集划分成训练集和测试集\n",
    "train_X,valid_X,train_y,valid_y = train_test_split(data['review'],data['label'],test_size=0.3,random_state=42)\n",
    " \n",
    "train_X.shape,train_y.shape,valid_X.shape,valid_y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c9bf1",
   "metadata": {},
   "source": [
    "((4403,), (4403,), (1887,), (1887,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7559d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型构建\n",
    "model_tfidf = TFIDF(min_df=5, max_features=5000, ngram_range=(1,3), use_idf=1, smooth_idf=1)\n",
    "# 学习idf vector\n",
    "model_tfidf.fit(train_X)\n",
    "# 把文档转换成 X矩阵（该文档中该特征词出现的频次），行是文档个数，列是特征词的个数\n",
    "train_vec = model_tfidf.transform(train_X)\n",
    " \n",
    "# 模型训练\n",
    "model_SVC = LinearSVC()\n",
    "clf = CalibratedClassifierCV(model_SVC)\n",
    "clf.fit(train_vec,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5efa1",
   "metadata": {},
   "source": [
    "CalibratedClassifierCV(base_estimator=LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c45239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正例: 1686\n",
      "负例: 201\n"
     ]
    }
   ],
   "source": [
    "# 把文档转换成矩阵\n",
    "valid_vec = model_tfidf.transform(valid_X)\n",
    "# 验证\n",
    "pre_valid = clf.predict_proba(valid_vec)\n",
    " \n",
    "pre_valid = clf.predict(valid_vec)\n",
    "print('正例:',sum(pre_valid == 1))\n",
    "print('负例:',sum(pre_valid == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fa72d",
   "metadata": {},
   "source": [
    "正例: 1686\n",
    "负例: 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5617f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.7270800211976682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "score = accuracy_score(pre_valid,valid_y)\n",
    "print(\"准确率:\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d0cdc",
   "metadata": {},
   "source": [
    "准确率: 0.7270800211976682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727da6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数： 4888\n",
      "正样本数： 2444\n",
      "负样本数： 2444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_balanced_words(size,\n",
    "                       positive_comment=data[data['label'] == 1],\n",
    "                       negtive_comment=data[data['label'] == 0]):\n",
    "    word_size = size // 2\n",
    "    #获取正负评论数\n",
    "    num_pos = positive_comment.shape[0]\n",
    "    num_neg = negtive_comment.shape[0]\n",
    "    #     当 正(负)品论数中<采样数量/2 时，进行上采样，否则都是下采样；\n",
    "    #     其中pandas的sample方法里的repalce参数代表是否进行上采样，默认不进行\n",
    "    balanced_words = pd.concat([\n",
    "        positive_comment.sample(word_size,\n",
    "                                replace=num_pos < word_size,\n",
    "                                random_state=0),\n",
    "        negtive_comment.sample(word_size,\n",
    "                               replace=num_neg < word_size,\n",
    "                               random_state=0)\n",
    "    ])\n",
    "    #     打印样本个数\n",
    "    print('样本总数：', balanced_words.shape[0])\n",
    "    print('正样本数：', balanced_words[data['label'] == 1].shape[0])\n",
    "    print('负样本数：', balanced_words[data['label'] == 0].shape[0])\n",
    "    print('')\n",
    "    return balanced_words\n",
    " \n",
    "data_4888 = get_balanced_words(4888)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a7ed2",
   "metadata": {},
   "source": [
    "样本总数： 4888\n",
    "正样本数： 2444\n",
    "负样本数： 2444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a9365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3421,), (3421,), (1467,), (1467,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF  # 原始文本转化为tf-idf的特征矩阵\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# 将有标签的数据集划分成训练集和测试集\n",
    "train_X,valid_X,train_y,valid_y = train_test_split(data_4888['review'],data_4888['label'],test_size=0.3,random_state=23)\n",
    " \n",
    "train_X.shape,train_y.shape,valid_X.shape,valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d999edd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c730476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型构建\n",
    "model_tfidf = TFIDF(min_df=2, max_features=5000, ngram_range=(1,3), use_idf=1, smooth_idf=1)\n",
    "# 学习idf vector\n",
    "model_tfidf.fit(train_X)\n",
    "# 把文档转换成 X矩阵（该文档中该特征词出现的频次），行是文档个数，列是特征词的个数\n",
    "train_vec = model_tfidf.transform(train_X)\n",
    " \n",
    "# 模型训练\n",
    "model_SVC = LinearSVC()\n",
    "clf = CalibratedClassifierCV(model_SVC)\n",
    "clf.fit(train_vec,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f6d8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正例: 442\n",
      "负例: 1025\n"
     ]
    }
   ],
   "source": [
    "# 把文档转换成矩阵\n",
    "valid_vec = model_tfidf.transform(valid_X)\n",
    "# 验证\n",
    "pre_valid = clf.predict_proba(valid_vec)\n",
    " \n",
    "pre_valid = clf.predict(valid_vec)\n",
    "print('正例:',sum(pre_valid == 1))\n",
    "print('负例:',sum(pre_valid == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cb9e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.7034764826175869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "score = accuracy_score(pre_valid,valid_y)\n",
    "print(\"准确率:\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ce3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "posdata=pd.DataFrame(posdata).dropna(axis=0)\n",
    "posdata.columns=['comment']\n",
    " \n",
    "negdata=pd.DataFrame(negdata).dropna(axis=0)\n",
    "negdata.columns=['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9140b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用jieba中文分词 \n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    " \n",
    "#格式转换 否则会报错  'float' object has no attribute 'decode'\n",
    "df1 = pd.DataFrame(posdata.astype(str))\n",
    " \n",
    "def chinese_word_cut(mytext):\n",
    "    return ' '.join(jieba.cut(mytext))\n",
    " \n",
    "#增加一列数据\n",
    "df1['content_cutted'] = df1['comment'].apply(chinese_word_cut)\n",
    " \n",
    " \n",
    " \n",
    "#格对负面评论进行操作\n",
    "df2 = pd.DataFrame(negdata.astype(str))\n",
    " \n",
    "def chinese_word_cut(mytext):\n",
    "    return ' '.join(jieba.cut(mytext))\n",
    " \n",
    "#增加一列数据\n",
    "df2['content_cutted'] = df2['comment'].apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3d5ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 1733)\n",
      "  (0, 856)\t0.09703003014893513\n",
      "  (0, 1543)\t0.3985651756062984\n",
      "  (0, 365)\t0.32450684748810255\n",
      "  (0, 764)\t0.25345356658225754\n",
      "  (0, 1727)\t0.3427323888129733\n",
      "  (0, 1679)\t0.1652275888721542\n",
      "  (0, 1260)\t0.24891737206353892\n",
      "  (0, 649)\t0.21193595767880338\n",
      "  (0, 307)\t0.3642886289248343\n",
      "  (0, 247)\t0.18253393657321682\n",
      "  (0, 1557)\t0.4029461420428512\n",
      "  (0, 1538)\t0.28662654844416097\n",
      "  (1, 1048)\t0.35319880925162583\n",
      "  (1, 1654)\t0.22706245851629792\n",
      "  (1, 1578)\t0.19891947797046905\n",
      "  (1, 0)\t0.23684689431833822\n",
      "  (1, 1643)\t0.3737215387598423\n",
      "  (1, 759)\t0.2191817410544371\n",
      "  (1, 1702)\t0.37737126750520106\n",
      "  (1, 1627)\t0.34207461237256465\n",
      "  (1, 585)\t0.3400901572538183\n",
      "  (1, 958)\t0.3702931455921666\n",
      "  (1, 967)\t0.13964728701852588\n",
      "  (1, 856)\t0.09282025314218026\n",
      "  (2, 1661)\t0.12784085889200988\n",
      "  :\t:\n",
      "  (4360, 346)\t0.5824062189353332\n",
      "  (4360, 117)\t0.48164002191698785\n",
      "  (4360, 1029)\t0.19562288769755032\n",
      "  (4360, 942)\t0.24226650261756333\n",
      "  (4360, 43)\t0.3107913486305313\n",
      "  (4360, 1109)\t0.2295397978502093\n",
      "  (4360, 452)\t0.23080203309502054\n",
      "  (4360, 1571)\t0.2524133050414913\n",
      "  (4360, 1496)\t0.2561301948777507\n",
      "  (4361, 530)\t0.3705166186997416\n",
      "  (4361, 72)\t0.38092418818588586\n",
      "  (4361, 819)\t0.3325573822387048\n",
      "  (4361, 1188)\t0.21426459138994008\n",
      "  (4361, 1590)\t0.21068326150734337\n",
      "  (4361, 310)\t0.605497872454418\n",
      "  (4361, 713)\t0.1482282392741995\n",
      "  (4361, 670)\t0.20517252980116266\n",
      "  (4361, 820)\t0.2585381035502816\n",
      "  (4361, 452)\t0.13851365059214635\n",
      "  (4362, 1119)\t0.578471683938091\n",
      "  (4362, 190)\t0.621397500125875\n",
      "  (4362, 1029)\t0.263584213653466\n",
      "  (4362, 127)\t0.21542039671170488\n",
      "  (4362, 1496)\t0.34511235778371724\n",
      "  (4362, 856)\t0.21035810708732294\n"
     ]
    }
   ],
   "source": [
    "path = '停用词汇总.txt'\n",
    "f = open(path,\"r\",encoding='utf-8').read()\n",
    "stopwords=list(f)\n",
    " \n",
    "#计算TF-IDF值\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    " \n",
    "#设置特征数\n",
    "n_features = 2000\n",
    " \n",
    " \n",
    "tf_vectorizer = TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                max_features=n_features,\n",
    "                                stop_words=stopwords,\n",
    "                                max_df = 0.99,\n",
    "                                min_df = 0.002) #去除文档内出现几率过大或过小的词汇\n",
    "tf = tf_vectorizer.fit_transform(df1.content_cutted)\n",
    " \n",
    "print(tf.shape)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6666ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1733)\n",
      "Topic #0:\n",
      "我们 入住 客人 宾馆 希望 反馈 服务 他们 服务员 再次 前台 感谢您 时候 预定 问题 光临 没有 工作 一下 人员\n",
      "\n",
      "Topic #1:\n",
      "不错 房间 比较 服务 可以 方便 早餐 就是 感觉 设施 还是 环境 价格 非常 干净 没有 入住 有点 不过 一般\n",
      "\n",
      "Topic #2:\n",
      "床单 门前 花园 面对 为什么 良好 高速 西餐 一半 接送 出口 地理 超好 同等 绝佳 花园式 稍远 中心 冬天 人民\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LDA分析\n",
    "\n",
    " \n",
    "#设置主题数\n",
    "n_topics = 3\n",
    " \n",
    "lda = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)\n",
    " \n",
    "#显示主题数 model.topic_word_\n",
    "# print(lda.components_)\n",
    "#几个主题就是几行 多少个关键词就是几列 \n",
    "print(lda.components_.shape)                         \n",
    "def print_top_words(model, tf_feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):  # lda.component相当于model.topic_word_\n",
    "        print('Topic #%d:' % topic_idx)\n",
    "        print(' '.join([tf_feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print(\"\")\n",
    "# 定义好函数之后 暂定每个主题输出前20个关键词\n",
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d608444",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyLDAvis' has no attribute 'gensim_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_450/3883092080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mred_vis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_vectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred_vis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyLDAvis' has no attribute 'gensim_model'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import importlib\n",
    "import pyLDAvis\n",
    "importlib.reload(pyLDAvis)\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "red_vis_data = pyLDAvis.gensim_model.prepare(lda,tf,tf_vectorizer)\n",
    "pyLDAvis.display(red_vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7242348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
